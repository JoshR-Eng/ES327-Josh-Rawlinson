@article{rosendo_distributed_2022,
    title = {Distributed intelligence on the {Edge}-to-{Cloud} {Continuum}: {A} systematic literature review},
    volume = {166},
    issn = {0743-7315},
    shorttitle = {Distributed intelligence on the {Edge}-to-{Cloud} {Continuum}},
    url = {https://www.sciencedirect.com/science/article/pii/S0743731522000843},
    doi = {10.1016/j.jpdc.2022.04.004},
    abstract = {The explosion of data volumes generated by an increasing number of applications is strongly impacting the evolution of distributed digital infrastructures for data analytics and machine learning (ML). While data analytics used to be mainly performed on cloud infrastructures, the rapid development of IoT infrastructures and the requirements for low-latency, secure processing has motivated the development of edge analytics. Today, to balance various trade-offs, ML-based analytics tends to increasingly leverage an interconnected ecosystem that allows complex applications to be executed on hybrid infrastructures where IoT Edge devices are interconnected to Cloud/HPC systems in what is called the Computing Continuum, the Digital Continuum, or the Transcontinuum. Enabling learning-based analytics on such complex infrastructures is challenging. The large scale and optimized deployment of learning-based workflows across the Edge-to-Cloud Continuum requires extensive and reproducible experimental analysis of the application execution on representative testbeds. This is necessary to help understand the performance trade-offs that result from combining a variety of learning paradigms and supportive frameworks. A thorough experimental analysis requires the assessment of the impact of multiple factors, such as: model accuracy, training time, network overhead, energy consumption, processing latency, among others. This review aims at providing a comprehensive vision of the main state-of-the-art libraries and frameworks for machine learning and data analytics available today. It describes the main learning paradigms enabling learning-based analytics on the Edge-to-Cloud Continuum. The main simulation, emulation, deployment systems, and testbeds for experimental research on the Edge-to-Cloud Continuum available today are also surveyed. Furthermore, we analyze how the selected systems provide support for experiment reproducibility. We conclude our review with a detailed discussion of relevant open research challenges and of future directions in this domain such as: holistic understanding of performance; performance optimization of applications; efficient deployment of Artificial Intelligence (AI) workflows on highly heterogeneous infrastructures; and reproducible analysis of experiments on the Computing Continuum.},
    urldate = {2026-02-07},
    journal = {Journal of Parallel and Distributed Computing},
    author = {Rosendo, Daniel and Costan, Alexandru and Valduriez, Patrick and Antoniu, Gabriel},
    month = aug,
    year = {2022},
    note = {109 citations (Semantic Scholar/DOI) [2026-02-07]
TLDR: This review aims at providing a comprehensive vision of the main state-of-the-art libraries and frameworks for machine learning and data analytics available today and describes the main learning paradigms enabling learning-based analytics on the Edge-to-Cloud Continuum.},
    keywords = {Big Data Analytics, Computing Continuum, Distributed intelligence, Edge computing, Reproducibility},
    pages = {71--94},
}
@article{mao_green_2024,
    title = {Green {Edge} {AI}: {A} {Contemporary} {Survey}},
    volume = {112},
    issn = {1558-2256},
    shorttitle = {Green {Edge} {AI}},
    url = {https://ieeexplore.ieee.org/document/10637271},
    doi = {10.1109/JPROC.2024.3437365},
    abstract = {Artificial intelligence (AI) technologies have emerged as pivotal enablers across a multitude of industries, including consumer electronics, healthcare, and manufacturing, largely due to their significant resurgence over the past decade. The transformative power of AI is primarily derived from the utilization of deep neural networks (DNNs), which require extensive data for training and substantial computational resources for processing. Consequently, DNN models are typically trained and deployed on resource-rich cloud servers. However, due to potential latency issues associated with cloud communications, deep learning (DL) workflows (e.g., DNN training and inference) are increasingly being transitioned to wireless edge networks in proximity to end-user devices (EUDs). This shift is designed to support latency-sensitive applications and has given rise to a new paradigm of edge AI, which will play a critical role in upcoming sixth-generation (6G) networks to support ubiquitous AI applications. Despite its considerable potential, edge AI faces substantial challenges, mostly due to the dichotomy between the resource limitations of wireless edge networks and the resource-intensive nature of DL. Specifically, the acquisition of large-scale data, as well as the training and inference processes of DNNs, can rapidly deplete the battery energy of EUDs. This necessitates an energy-conscious approach to edge AI to ensure both optimal and sustainable performance. In this article, we present a contemporary survey on green edge AI. We commence by analyzing the principal energy consumption components of edge AI systems to identify the fundamental design principles of green edge AI. Guided by these principles, we then explore energy-efficient design methodologies for the three critical tasks in edge AI systems, including training data acquisition, edge training, and edge inference. Finally, we underscore potential future research directions to further enhance the energy efficiency (EE) of edge AI.},
    number = {7},
    urldate = {2026-02-10},
    journal = {Proceedings of the IEEE},
    author = {Mao, Yuyi and Yu, Xianghao and Huang, Kaibin and Angela Zhang, Ying-Jun and Zhang, Jun},
    month = jul,
    year = {2024},
    note = {62 citations (Semantic Scholar/DOI) [2026-02-10]
TLDR: A contemporary survey on green edge AI is presented, analyzing the principal energy consumption components of edge AI systems to identify the fundamental design principles of green edge AI, and exploring energy-efficient design methodologies for the three critical tasks in edge AI systems, including training data acquisition, edge training, and edge inference.},
    keywords = {6G mobile communication, Artificial intelligence, Cloud computing, Data acquisition, Edge AI, Edge computing, Energy consumption, Energy efficiency, Federated learning, Surveys, Training, Wireless networks, edge artificial intelligence (AI), edge inference, energy efficiency (EE), federated learning (FL), green AI, mobile edge computing (MEC), sixth-generation (6G) wireless networks},
    pages = {880--911},
}
@article{barbierato_toward_2024,
    title = {Toward {Green} {AI}: {A} {Methodological} {Survey} of the {Scientific} {Literature}},
    volume = {12},
    issn = {2169-3536},
    shorttitle = {Toward {Green} {AI}},
    url = {https://ieeexplore.ieee.org/document/10418137},
    doi = {10.1109/ACCESS.2024.3360705},
    abstract = {The pervasive deployment of Deep Learning models has recently prompted apprehensions regarding their ecological footprint, owing to the exorbitant levels of energy consumption necessitated by the training and inference processes. The term “Red AI” is employed to denote artificial intelligence (AI) models that undergo training using resource-intensive methodologies on very large datasets. This practice can engender substantial energy usage and emissions of carbon, thereby opposing “Green AI. ” The latter concept alludes to AI models designed for similar efficiency and reduced environmental impact. This objective is realized through the utilization of smaller datasets, less computationally intensive training techniques, or sustainable energy resources. While Red AI prioritizes accuracy and performance, Green AI emphasizes efficiency and sustainability. Given that both paradigms exhibit advantages and limitations, the debates around the topics have burgeoned in the scientific arena, delving into novel algorithms, hardware innovations, and improved data utilization techniques aimed at mitigating the ecological consequences of intricate applications such as GPT and BERT. Nevertheless, due to the relative novelty of this debate, not much effort has been dedicated yet to contextualizing the essence of Red AI and the prospects of Green AI in a coherent framework. Within this context, the present work contributes by meticulously delineating both domains through a multifaceted analysis of their causes and ramifications, described from the points of computer architectures, data structures, and algorithms. Additionally, the study reviews notable instances of study cases based on complex Red AI models. The primary contribution of this article encompasses a comprehensive survey of Red and Green AI, stemming from a selection of the literature performed by the authors, subsequently organized into distinct clusters. These clusters encompass i) articles that qualitatively or quantitatively address the issue of Red AI, identifying Green AI as a plausible remedy, ii) articles offering insights into the environmental impact associated with the deployment of extensive Deep Learning models, and iii) articles introducing the techniques underpinning Green AI, aiming at mitigating the cost of Red AI. The outcome emerging from the analysis performed by this work consists of a compromise between sustainability in contrast to the performance of AI tools. Unless the complex training and inference procedures of software models mitigate their environmental impact, it will be necessary to decrease the level of accuracy of production systems, inevitably conflicting with the objective of the major AI vendors. The outcomes of this work would be beneficial to scholars pursuing intricate Deep Learning architectures in scientific research, as well as AI enterprises struggling with the protracted training demands of commercial products within the realms of Computer Vision and Natural Language Processing.},
    urldate = {2026-02-10},
    journal = {IEEE Access},
    author = {Barbierato, Enrico and Gatti, Alice},
    year = {2024},
    note = {30 citations (Semantic Scholar/DOI) [2026-02-10]
TLDR: A comprehensive survey of Red and Green AI is undertaken, meticulously delineating both domains through a multifaceted analysis of their causes and ramifications, described from the points of computer architectures, data structures, and algorithms.},
    keywords = {Artificial intelligence, Biological system modeling, Computational modeling, Computer architecture, Environmental monitoring, Green AI, Green products, Surveys, Training, environmental impact, red AI, survey},
    pages = {23989--24013},
}