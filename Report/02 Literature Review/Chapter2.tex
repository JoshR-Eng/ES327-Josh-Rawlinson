% !TEX root =  ../Report.tex

\chapter{Literature Review}
\label{sec: Lit Review}


%==============================================================
%                        section 1. 
%        
\section{Battery State Estimation: Tasks and Challenges}
%==============================================================


%==============================================================
%                       section 2. 
%        
\section{State-of-Charge \& State-of-Health Estimation}
%==============================================================
\subsection{Model-based Approach}


\subsection{Machine-Learning Based Approach}


\subsection{Real-world Data and Operational Constraints}



%==============================================================
%                       section 3. 
%         
\section{Temporal Deep Learning Architectures}
%==============================================================
\subsection{Machine Learning for Sequence Modelling}


\subsection{Recurrent Neural Networks}


\subsection{Convolutional and Temporal Convolution Networks}



%==============================================================
%                       section 4. 
%                      
\section{Edge and On-Device Intelligence}
%==============================================================
\subsection{Distributing Cloud AI to the Edge}

The traditional paradigm of Cloud-centric AI, while offering virtually unlimited computational resources, introduces unacceptable latency and connectivity dependencies for safety-critical systems - such as Battery Management \cite{rosendo_distributed_2022}. As discussed by Rosendo et al., the transmission of high-frequency data to a central server incurs significant bandwidth costs and privacy risks while the growing number of interconnected IoT devices elevates these concerns. Consequently, the industry is witnessing a migration towards "Edge Intelligence" where inference occurs directly at the source of the data. This shift, however, imposes strict constraints on the computational availability and resource consumption, necessitating a departure from general-purpose computing towards specialised, energy-efficient hardware architectures \cite{mao_green_2024}.
However, as noted by Barbierato \& Gatti \cite{barbierato_toward_2024}, metrics are often limited to theoretical "Floating-Point Operations Per Second" (FLOPS) rather then empirical energy measurements. This abstracts away from critical hardware effects like memory traffic, data precision, power modes and SoC utilisation. 


\subsection{TinyML to GPU-Class Edge Devices}




\subsection{Precision Trade-offs: FP32, INT8, and the cost of accuracy}




\subsection{Power, Energy and Resource Measurement on NVIDIA Jetson}




%==============================================================
%                       section 5. 
%                      
\section{Summary of Gaps and Research Questions}
%==============================================================
